---
layout: post
title:  Machine Learning keywords
date:   2020-12-03 11:00:00 +0800
categories: computing
---

**Machine Learning**  
hypothesis vs. ground-truth  
classification and regression  
supervised vs. unsupervised  
induction vs. deduction  

*NFL theorem*:
<https://en.wikipedia.org/wiki/No_free_lunch_theorem>

*Machine Learning*: Arthur Samuel, 1901-1990, in IBM.

Strategies to obtain test set:
1.hold-out; 2.cross-validation; 3.bootstrapping(bias)

parameters:
algorithm vs. model

**Quantify the performance**  
For regression, the widely adopted performance masurement is mean squared error.  
precision and recall (P-R diagram):BEP(break-even point); F1 harmonic mean  
ROC(Reciever Operating Characteristic) and AUC(Area Under ROC Curve), cost  
hypothesis test  
binomial test; t-test; McNemar-test; Friedman-test   
bias vs. variance vs. noise  

**Linear Model**  
$$f(\mathbf{x}_i)=\mathbf{\omega}^T\mathbf{x}_i+b$$  
linear regression   
square loss  
classification $\rightarrow$ unit-step function, surrogate function: logistic function

LDA(Linear Discriminant Analysis) [Fisher, 1936]  
multi-classification:1.OvO;2.OvR;3.MvM(ECOC,Error Correcting Output Codes)  
class-imbalance: rescaling;undersampling(EasyEnsemble, Liu et al.,2009),oversampling(SMOTE, Chawla et al.,2002),thresholkd-moving;  

**Decision Tree**  

**Neural Networks** 
